{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022_AI_boot_camp_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesol-park/2022_HY_AIBootCamp/blob/main/2022_AI_boot_camp_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnAAhZ9B2CLN"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install pytorch-lightning\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Datset\n",
        "# https://tutorials.pytorch.kr/beginner/blitz/cifar10_tutorial.html\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print('*==========Train Set==========*')\n",
        "print(train_set)\n",
        "print('*========== Test Set ==========*')\n",
        "print(test_set)"
      ],
      "metadata": {
        "id": "ZsKwVv8L2DkB",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img = train_set[1][0]\n",
        "label = train_set[1][1]\n",
        "img = img.numpy()\n",
        "\n",
        "print(img.shape)\n",
        "print(f'{classes[label]}-{label}')\n",
        "\n",
        "origin_img = img / 2 + 0.5 # unnormalized\n",
        "plt.imshow(np.transpose(origin_img, (1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tv4KDkcFw8_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning import LightningDataModule\n",
        "\n",
        "class CustomDataModule(LightningDataModule):\n",
        "  def __init__(self, training_set, test_set, batch_size=128, num_workers=2):\n",
        "    super().__init__()\n",
        "    self.training_set = training_set\n",
        "    self.test_set = test_set\n",
        "\n",
        "    # set parameters\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "  #how to make a batch\n",
        "  def collate_function(self, batch):    \n",
        "    new_x = [x.flatten() for x, _ in batch]\n",
        "    new_y = [torch.tensor(y, dtype=torch.long) for _, y in batch]\n",
        "    return [torch.stack(new_x), torch.stack(new_y)]\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.training_set, batch_size=self.batch_size, \n",
        "                      num_workers=self.num_workers, shuffle=True, \n",
        "                      collate_fn=self.collate_function)\n",
        "    \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_set, batch_size=self.batch_size, \n",
        "                      num_workers=self.num_workers, \n",
        "                      collate_fn=self.collate_function)\n",
        "    \n",
        "# data_module = CustomDataModule(train_set, test_set)\n",
        "# trainer.fit(model, datamodule = data_module)"
      ],
      "metadata": {
        "id": "rz_LNIoISow4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DeepNeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, label_size, layer_size=64):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.layer_size = layer_size\n",
        "    self.label_size = label_size\n",
        "    self.set_layer()\n",
        "  \n",
        "  def set_layer(self):\n",
        "    # Build layer\n",
        "    self.first_layer = nn.Linear(self.input_size, self.layer_size)\n",
        "    self.second_layer = nn.Linear(self.layer_size, self.layer_size)\n",
        "    self.last_layer = nn.Linear(self.layer_size, self.label_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Define operation\n",
        "    x = self.first_layer(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.second_layer(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.last_layer(x)\n",
        "    \n",
        "    return x"
      ],
      "metadata": {
        "id": "yb_6REzQdk1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import LightningModule\n",
        "\n",
        "from torch.nn import CrossEntropyLoss, Softmax\n",
        "from torch.optim import Adam\n",
        "\n",
        "class LitCIFAR10Model(LightningModule):\n",
        "  def __init__(self, model, learning_rate=1e-3):\n",
        "    super().__init__()\n",
        "    self.model =  model\n",
        "    self.lr = learning_rate\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.model(x)\n",
        "    return out\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer=Adam(self.parameters(), lr=self.lr)\n",
        "    return optimizer\n",
        " \n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self(x)\n",
        "    loss = self.loss_function(logits, y)\n",
        "    predict = torch.argmax(logits, dim=1)    \n",
        "    return {'loss': loss, 'predict': predict, 'answer': y}\n",
        "\n",
        "  def training_epoch_end(self, outputs):\n",
        "    loss = [output['loss'] for output in outputs]\n",
        "    avg_loss = sum(loss) / len(outputs)\n",
        "    self.logger.experiment.add_scalar(\"Loss/Epoch\",\n",
        "                                      avg_loss,\n",
        "                                      self.current_epoch)\n",
        "\n",
        "  def predict_step(self, batch, batch_idx):\n",
        "    x, y = batch\n",
        "    logits = self.model(x)\n",
        "    logits = Softmax(dim=1)(logits)\n",
        "    predict = torch.argmax(logits, dim=1)\n",
        "    return predict\n",
        "  \n",
        "  def loss_function(self, output, target):\n",
        "    return CrossEntropyLoss()(output, target)"
      ],
      "metadata": {
        "id": "RtOqJ__plMo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger('./log_DeepNN', name=\"LitCIFAR10-DeepNN-Adam-128,1e-3\")\n",
        "data_module = CustomDataModule(train_set, test_set)\n",
        "\n",
        "architecture = DeepNeuralNet(32*32*3, 10) #32*32(pixels)*3 channels, labels\n",
        "model = LitCIFAR10Model(architecture)\n",
        "\n",
        "trainer = Trainer(max_epochs=10, accelerator='gpu', devices=[0], logger=logger)\n",
        "#trainer = Trainer(max_epochs=10, accelerator='cpu', logger=logger)\n",
        "\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "metadata": {
        "id": "qlsV09G08nkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"./log_DeepNN\""
      ],
      "metadata": {
        "id": "2lJDVMiRlluH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
        "predict = torch.cat(predict)\n",
        "\n",
        "answer = [batch[1] for batch in data_module.test_dataloader()]\n",
        "answer = torch.cat(answer)\n",
        "\n",
        "correct = (predict == answer).sum()\n",
        "total = answer.shape[0]\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f'correct: {correct}, total: {total}, accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "# You can use torchmetrics\n",
        "import torchmetrics\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(predict, answer)\n",
        "print(f\"accuracy-torchmetrics: {acc}\")"
      ],
      "metadata": {
        "id": "EBS0NhH1_oGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Conv2D(nn.Module):\n",
        "  def __init__(self, label_size):\n",
        "    super().__init__()\n",
        "    self.label_size = label_size\n",
        "    self.set_layer()\n",
        "  \n",
        "  def set_layer(self):\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x   \n"
      ],
      "metadata": {
        "id": "vt1vxxNusesG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Custom2DDataModule(LightningDataModule):\n",
        "  def __init__(self, training_set, test_set, batch_size=128, num_workers=2):\n",
        "    super().__init__()\n",
        "    self.training_set = training_set\n",
        "    self.test_set = test_set\n",
        "\n",
        "    # set parameters\n",
        "    self.batch_size = batch_size\n",
        "    self.num_workers = num_workers\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(self.training_set, batch_size=self.batch_size, \n",
        "                      num_workers=self.num_workers, shuffle=True,)\n",
        "    \n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(self.test_set, batch_size=self.batch_size, \n",
        "                      num_workers=self.num_workers,)"
      ],
      "metadata": {
        "id": "AXUUpHcfnGE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = Custom2DDataModule(train_set, test_set)\n",
        "\n",
        "logger = TensorBoardLogger('./log_Conv2D', name=\"LitCIFAR10-Conv2D-Adam-128,1e-3\", log_graph=True,)\n",
        "\n",
        "architecture = Conv2D(10)\n",
        "model = LitCIFAR10Model(architecture)\n",
        "trainer = Trainer(max_epochs=10, accelerator='gpu', devices=[0], logger=logger)\n",
        "#trainer = Trainer(max_epochs=10, accelerator='cpu', logger=logger)\n",
        "\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "metadata": {
        "id": "NFm2T0ECmVhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"./log_Conv2D\""
      ],
      "metadata": {
        "id": "4Q6v-X-hon4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "\n",
        "predict = trainer.predict(model, dataloaders=data_module.test_dataloader())\n",
        "predict = torch.cat(predict)\n",
        "\n",
        "answer = [batch[1] for batch in data_module.test_dataloader()]\n",
        "answer = torch.cat(answer)\n",
        "\n",
        "acc = torchmetrics.functional.accuracy(predict, answer)\n",
        "print(f\"accuracy-torchmetrics: {acc}\")"
      ],
      "metadata": {
        "id": "gPm7DR-5qsfa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}